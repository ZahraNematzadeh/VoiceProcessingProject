# -*-Python-*-

import example.external_configurables
import leaf_audio.frontend
import leaf_audio.models
import leaf_audio.pooling
import leaf_audio.postprocessing

# HYPERPARAMETERS
train.workdir ='C:/Users/zahra/Desktop/FarzanehFiles/Codes/2_Code_TT_AugPercentAllTrain_TV/OnlineAugmentation/git_leaf/SavedModels'
#train.dataset_train_df = oversampled_train_df,
#train.dataset_val_df = oversampled_val_df,
train.train_dir = 'C:/Users/zahra/Desktop/FarzanehFiles/Codes/2_Code_TT_AugPercentAllTrain_TV/OnlineAugmentation/OutputOnline/1.e/70_20_10/oversampled/train'
train.val_dir ='C:/Users/zahra/Desktop/FarzanehFiles/Codes/2_Code_TT_AugPercentAllTrain_TV/OnlineAugmentation/OutputOnline/1.e/70_20_10/oversampled/Val'
train.num_epochs = 10
train.learning_rate = 1e-4
train.batch_size = 64
train.num_classes = 2

# AUDIO PRE-PROCESSING
data.prepare.transform_fns = [@data.align, @data.loudness_normalization]
loudness_normalization.target_db = 15.0
loudness_normalization.max_gain_db = 30.0
align.seq_len = 16000

# PICK YOUR ENCODER
AudioClassifier.encoder = @ConvNet()

# ENCODER PARAMETERS
ConvNet.filters = [64, 128, 256, 256, 512, 512]
ConvBlock.activation = 'relu'
ConvBlock.dropout = 0.1